<!DOCTYPE HTML>
<html lang="pt" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Téorica 08 - Teóricas de DAA</title>
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="chapter_1.html"><strong aria-hidden="true">1.</strong> Teórica 01</a></li><li class="chapter-item expanded "><a href="chapter_2.html"><strong aria-hidden="true">2.</strong> Teórica 02</a></li><li class="chapter-item expanded "><a href="chapter_3.html"><strong aria-hidden="true">3.</strong> Teórica 03</a></li><li class="chapter-item expanded "><a href="chapter_4.html"><strong aria-hidden="true">4.</strong> Teórica 04</a></li><li class="chapter-item expanded "><a href="chapter_5.html"><strong aria-hidden="true">5.</strong> Teórica 05</a></li><li class="chapter-item expanded "><a href="chapter_6.html"><strong aria-hidden="true">6.</strong> Teórica 06</a></li><li class="chapter-item expanded "><a href="chapter_7.html"><strong aria-hidden="true">7.</strong> Teórica 07</a></li><li class="chapter-item expanded "><a href="chapter_8.html" class="active"><strong aria-hidden="true">8.</strong> Téorica 08</a></li><li class="chapter-item expanded "><a href="chapter_9.html"><strong aria-hidden="true">9.</strong> Teórica 09</a></li><li class="chapter-item expanded "><a href="chapter_10.html"><strong aria-hidden="true">10.</strong> Teórica 10</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Teóricas de DAA</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="redes-neuronais-artificiais"><a class="header" href="#redes-neuronais-artificiais">Redes Neuronais Artificiais</a></h1>
<ul>
<li>São modelos de <em>machine learning</em> que funcionam de forma análoga ao cérebro humano. É um processador paralelo composto por nodos de processamento singulares (neurónios);</li>
<li>O conhecimento é guardado em conexões entre os neurónios;</li>
<li>O conhecimento é obtido de um ambiente (dados), através de um processo de aprendizagem (algoritmo de treino) que ajustam os parâmetros da rede;</li>
</ul>
<h2 id="benefíciosrazões-para-o-sucesso"><a class="header" href="#benefíciosrazões-para-o-sucesso">Benefícios/Razões para o Sucesso</a></h2>
<ul>
<li><strong>Aprendizagem/Generalização</strong>: permite a obtenção de novo conhecimento do ambiente;</li>
<li><strong>Processamento paralelo massivo</strong>: permite que tarefas complexas sejam efetuadas num curto espaço de tempo;</li>
<li><strong>Não linear</strong>: útil para muitos problemas reais;</li>
<li><strong>Adaptabilidade</strong>: podem adaptar a sua topologia de acordo com as mudanças no ambiente;</li>
<li><strong>Robustez e degradação suave</strong>: disponível para ignorar ruído e atributos irrelevantes, capaz de lidar com informação em falta de forma eficiente;</li>
<li><strong>Flexibilidade</strong>: tem um grande domínio de aplicabilidade;</li>
<li><strong>Usabilidade</strong>: pode ser utilizada como &quot;<em>black boxes</em>&quot;, não precisa de conhecimento explícito acerca da função a aprender.</li>
</ul>
<h2 id="tipos-comuns-de-aplicação"><a class="header" href="#tipos-comuns-de-aplicação">Tipos Comuns de Aplicação</a></h2>
<ul>
<li>Memória Associativa;</li>
<li>Classificação/Diagnóstico;</li>
<li>Reconhecimento de padrões;</li>
<li>Regressão;</li>
<li>Controlo;</li>
<li>Otimização;</li>
<li>Filtragem de dados/compressão;</li>
<li>etc...</li>
</ul>
<h2 id="neurónios-artificiais"><a class="header" href="#neurónios-artificiais">Neurónios Artificiais</a></h2>
<ul>
<li>Recebem um conjunto de <em>inputs</em>, dados ou conexões (\( x_i \));</li>
<li>Têm um peso (valor numérico) associado a cada conexão (\( w_i \));</li>
<li>Cada neurónio calcula a sua ativação baseado nos valores de <em>input</em> e dos pesos das conexões;</li>
<li>O sinal calculado é passado para o <em>output</em> após ser filtrada pela função de ativação (\( f() \)).</li>
</ul>
<p><img src="images/nodes.png" alt="image Neurónios Artificiais" /></p>
<h2 id="funções-de-ativação"><a class="header" href="#funções-de-ativação">Funções de Ativação</a></h2>
<ul>
<li><em>Sigmoid</em>/Logística;</li>
<li>Linear;</li>
<li>Tangente hiperbólica (<em>Tanh</em>);</li>
<li>Gaussiana;</li>
<li>ReIU (<em>linear rectified</em>). </li>
</ul>
<p><img src="images/activation_functions.png" alt="image Funções de Ativação" /></p>
<h2 id="arquiteturas-de-redes-topologias"><a class="header" href="#arquiteturas-de-redes-topologias">Arquiteturas de Redes (topologias)</a></h2>
<ul>
<li>Forma como os nodos se encontram interconectados numa rede estruturada;</li>
<li>Existem múltiplos tipos de arquiteturas, cada uma com o seu próprio potencial, tendo duas categorias: <strong>supervisionadas</strong> e <strong>não supervisionadas</strong>.</li>
</ul>
<h2 id="topologia-feedforward"><a class="header" href="#topologia-feedforward">Topologia <em>Feedforward</em></a></h2>
<ul>
<li><em><strong>Multilayer Perceptron (MLP)</strong></em> - <em>Feedforward</em> totalmente conectado numa rede neuronal com múltiplas camadas intermédias.</li>
</ul>
<p><img src="images/feedforward_topology.png" alt="image Topologia Feedforward" /></p>
<h2 id="problemas-de-classificação"><a class="header" href="#problemas-de-classificação">Problemas de Classificação</a></h2>
<p>Se usarmos modelos funcionais para para problemas de classificação, então teremos de converter os <em>outputs</em> do modelo (valores numéricos) nos valores desejados pelo atributo de <em>output</em> (nominais), isto é, em classes expectáveis.</p>
<p>Podemos escolher entre duas hipóteses: um neurónio a dividir o domínio ou <em>1-of-C</em>/<em>one-hot encoding</em>.</p>
<p>No último aso, teremos \( M \) <em>outputs</em> numéricos (1 por classe) e a classe correspondente ao maior valor é, geralmente, escolhida.</p>
<p>Neste caso, facilmente calculamos as probabilidades para cada classe (função <em>softmax</em>).</p>
<h2 id="treino"><a class="header" href="#treino">Treino</a></h2>
<p><strong>Dados</strong>: exemplos de treino que consistem em <em>inputs</em> e nos seus <em>outputs</em> desejáveis;</p>
<p><strong>Objetivo</strong>: arranjar os pesos das conexões de forma a minimizar a perda de cada função: no caso dos ANNs é a generalização do custo da função de regressão logística.</p>
<p>Existem múltiplos algoritmos de treino baseados no <em>descending gradient</em>:</p>
<ul>
<li>O mais usado é a <em>backpropagation</em>;</li>
<li>Outros: <em>Marquardt-Levenberg</em>, <em>Rprop</em>, <em>Quickprop</em>, etc...</li>
</ul>
<h2 id="algoritmo-de-backpropagation"><a class="header" href="#algoritmo-de-backpropagation">Algoritmo de <em>Backpropagation</em></a></h2>
<ul>
<li>Baseado no vetor gradiente da superfície de erro que define a direção do <em>maximum descent</em> - método semelhante ao descendente do gradiente;</li>
<li>Parâmetro importante: taxa de aprendizagem que define a distância qe um algoritmo anda;</li>
<li>A sequência destes movimentos lidam a um mínimo (no melhor caso, global);</li>
<li>Execuções do treino para um dado número de <em>epochs</em>: define o número de vezes que cada caso é treinado pela rede, sendo que os exemplos tipicamente são divididos em <em>batches</em> (subconjuntos de exemplos);</li>
<li>Configuração inicial da rede é, geralmente, gerada de forma aleatória;</li>
<li><strong>Critério de Paragem</strong>: número fixo de <em>epochs</em>, tempo e critério de convergência baseado num subconjunto de exemplos de validação.</li>
</ul>
<h3 id="fases"><a class="header" href="#fases">Fases</a></h3>
<ul>
<li><em><strong>Forward Propagation</strong></em>: calcula o valor de <em>output</em> para o vetor de <em>input</em> e o erro cometido;</li>
<li><em><strong>Backpropagation</strong></em>: dado o erro cometido, este é propagado para trás, ajustando os pesos das conexões da direção do seu decréscimo. É baseado no cálculo do gradiente utilizando a regra em cadeia para funções compostas.</li>
</ul>
<p><img src="images/phases_backpropagation.png" alt="image Fases" /></p>
<h2 id="suma"><a class="header" href="#suma">Suma</a></h2>
<ul>
<li>Embora existam muitas variantes de redes neuronais, cada uma pode ser definida em termos de:
<ul>
<li><strong>Função de ativação</strong>: transforma o <em>input</em> da rede de um nodo num único sinal de <em>output</em> que será propagado para a frente na rede;</li>
<li><strong>Arquitetura de Rede</strong> ou topologia: descreve o número de nodos do modelo e o número de camada e a forma como elas estão conectadas;</li>
<li><strong>Algoritmo de Treino</strong>: especifica como é que os pesos das conexões são definidos de forma a inibir ou excitar neurónios em proporção com o sinal de <em>input</em>.</li>
</ul>
</li>
</ul>
<h2 id="escolha-da-topologia-para-feedforward-annhiperparâmetros"><a class="header" href="#escolha-da-topologia-para-feedforward-annhiperparâmetros">Escolha da topologia para <em>feedforward</em> ANN/hiperparâmetros</a></h2>
<ul>
<li>Quando nodos de <em>input</em> e <em>output</em>?</li>
<li>Quantas camadas e nodos intermédios?</li>
<li>Como conectar os neurónios?</li>
<li>Conexões mais curtas?</li>
<li><strong>Modelo mais simples</strong>: <em>Feedforward Networks with fully interconnected layers</em> (MLP).</li>
</ul>
<h3 id="arquitetura-da-rede-topologia"><a class="header" href="#arquitetura-da-rede-topologia">Arquitetura da Rede (Topologia)</a></h3>
<ul>
<li>A capacidade da rede neuronal aprender é baseada na sua arquitetura ou em padrões e estruturas de neurónios interconectados;</li>
<li>Determina a complexidade das tarefas que podem ser aprendidas pela rede;
<ul>
<li>Geralmente, redes mais largas e complexas são capazes de identificar padrões mais súbtis e limites de decisões complexas;</li>
<li>No entanto, o poder da rede não é apenas em função do seu tamanho, mas sim da maneira que as suas unidades estão colocadas.
<ul>
<li>Número de camadas;</li>
<li>Direção do <em>flow</em> de informação;</li>
<li>Número de nodos em cada camada da rede.</li>
</ul>
</li>
</ul>
</li>
<li>O número de camadas escondidas, tipicamente:
<ul>
<li>1 camada tem capacidade para aproximar qualquer área de decisão linear (semiplano);</li>
<li>2 camadas aproximam qualquer área de decisão contínua (regiões convexas);</li>
<li>3 camadas aproximam qualquer área de decisão (regiões arbitrárias).</li>
</ul>
</li>
</ul>
<h3 id="número-de-nodos-em-cada-camada"><a class="header" href="#número-de-nodos-em-cada-camada">Número de Nodos em cada Camada</a></h3>
<ul>
<li>O número de nodos de <em>input</em> é pré-determinado pelo número de atributos dos dados de <em>input</em>;</li>
<li>O número de nodos de <em>output</em> é pré-determinado pelo número de resultados que devem ser modelados ou pelo número de classes no resultado;</li>
<li>O número de nodos escondidos é deixado a escolher ao utilizador antes de treinar o modelo, não havendo qualquer regra fiável para definir o número de neurónios na camada escondida:
<ul>
<li>Um grande número de neurónios terá tendência a deixar os resultados muito semelhantes aos dados de treino, correndo o risco de <em>overfitting</em>, ou seja, pode generalizar mal para dados desconhecidos;</li>
<li>Redes neuronais grandes também podem ser computacionalmente caras e lentas para treinar;</li>
<li>Um número pequeno de neurónios pode não ser suficiente para modelar a área de decisão pretendida;</li>
<li>Devem ser testados os valores de neurónios entre metade e o dobro dos neurónios presentes na camada de <em>input</em>;</li>
<li>Devemos utilizar o modelo que tenha menos nodos e resulte num desempenho adequado num <em>dataset</em> de validação.</li>
</ul>
</li>
</ul>
<h3 id="generalizaçãooverfitting"><a class="header" href="#generalizaçãooverfitting">Generalização/<em>Overfitting</em></a></h3>
<ul>
<li><em>Overtraining</em> uma ANN pode prevenir a generalização por <em>overfitting</em>. A ANN memorizará os casos de treino e não as regras de generalização, o treino pode ser parado mais cedo;</li>
<li>A regularização pode ser usada de forma semelhante à regressão logística/linear;</li>
<li>A probabilidade de <em>overfitting</em> aumenta se:
<ul>
<li>Tivermos poucos casos de treino (qualidade das amostras);</li>
<li>Tivermos demasiadas conexões (complexidade da rede).</li>
</ul>
</li>
</ul>
<h2 id="training-process-a-better-model"><a class="header" href="#training-process-a-better-model"><em>Training Process &quot;A Better Model&quot;</em></a></h2>
<h3 id="underfitting"><a class="header" href="#underfitting"><em>Underfitting</em></a></h3>
<p>Este modelo falha na complexidade necessária para capturar corretamente a complexidade inerente ao problema que se pretende resolver. Podemos reconhecer esta situação quando o erro é demasiado grande, tanto nos casos de treino e nos casos de (validação) teste.</p>
<h3 id="overfitting"><a class="header" href="#overfitting"><em>Overfitting</em></a></h3>
<p>Este modelo utiliza demasiados parâmetros e foi treinado em demasia.</p>
<p>Especificamente, aprendeu a identificar qualquer caso no conjunto de treino, tornando-se tão específica que não é capaz de generalizar para imagens semelhantes. Podemos reconhecer esta situação quando o erro nos casos de treino é muito menor que os casos de teste.</p>
<p>Medidas para reduzir o <em>overfitting</em>:</p>
<ul>
<li>Adicionar mais casos ao conjunto de treinos;</li>
<li>Utilizar arquiteturas que demonstraram generalizar bem;</li>
<li>Reduzir a complexidade da arquitetura de rede;</li>
<li>Usar <em>data augmentation</em>;</li>
<li>Adicionar normalização (<em>Batch Normalization Layer</em>);</li>
<li>Adicionar <em>dropout</em> (<em>Dropout Layer</em>).</li>
</ul>
<h2 id="training-process-learning-curves"><a class="header" href="#training-process-learning-curves"><em>Training Process &quot;Learning Curves&quot;</em></a></h2>
<ol>
<li>Um modelo que esteja em <em>underfit</em> que não tenha capacidade suficiente pode ser demonstrado como uma linha reta ou valores de ruída de uma perda relativamente grande, indicando que o modelo não foi capaz de aprender o <em>dataset</em>.
<ol>
<li><strong>Adicionar mais observações</strong>: podemos não ter dados suficientes para os padrões existentes terem sinais fortes;</li>
<li><strong>Adicionar mais atributos</strong>: ocasionalmente, este modelo está em <em>underfit</em>, porque os atributos são insuficientes;</li>
<li><strong>Reduzir a regularização do modelo</strong>: se tivermos parâmetros de regularização explícitos, devemos remover ou reduzir esses parâmetros;</li>
<li><strong>Aumento da capacidade do modelo</strong>: a capacidade do modelo pode não ser suficientemente grande para capturar ou aprender sinais existentes.</li>
</ol>
</li>
<li>Um modelo que esteja em <em>underfit</em> que precisa de mais treino pode ser demonstrado como um perda de treino que vai diminuindo até ao fim do gráfico. Isto indica que o modelo é capaz de aprender mais e melhores e o processo de treino foi parado prematuramente.
<ol>
<li><strong>Aumentar o número de <em>epochs</em></strong>: até a curva de validação para de melhorar. É uma boa altura para aumentar muito o número de <em>epochs</em> e adicionar uma paragem <em>early</em> de forma a identificar quantos <em>epochs</em> são requeridos;</li>
<li>Se estiver a demorar demasiado tempo para chegar ao mínimo para a curva de validação, devemos <strong>aumentar a taxa de aprendizagem</strong> para aumentar a travessia e adicionar um <em>callback</em> para ajustar, de forma automática, a taxa de aprendizagem.</li>
</ol>
</li>
<li>Um exemplo de um modelo em <em>overfit</em> pode ser demonstrado por um ponto de inflexão na <em>validation loss</em> que pode ser o ponto no qual se pode parar a experiência, visto ter demonstrado as dinâmicas do <em>overfitting</em>.
<ol>
<li>Regulariza o quão rápido um modelo aprende ao reduzir a sua taxa de aprendizagem. Adiciona um <em>callback</em> para, de forma automática, reduzir a taxa de aprendizagem como a <em>validation loss plateaus</em>;</li>
<li>Regulariza a capacidade do modelo de reduzir o número e/ou o tamanho das camadas escondidas;</li>
<li>Regulariza os pesos de forma a controlar a complexidade da rede;</li>
<li>Regulariza os padrões de ocorrência adicionar um <em>dropout</em> de forma a minimizar a chance de encontrar padrões que encaixem e gerem ruído nos dados.</li>
</ol>
</li>
<li>Um <em>dataset</em> de treino pode ser muito pequeno relativamente ao seu <em>dataset</em> de validação, esta situação pode ser identificada através de uma curva de aprendizagem para perda de treino que demonstra uma melhoria e uma semelhança com a curva de aprendizagem para <em>validation loss</em> que apresenta melhora, mas uma grande <em>gap</em> mantém-se entre as curvas.
<ol>
<li><strong>Adicionar mais observações</strong>: podemos não ter dados suficientes para capturar padrões presentes tanto nos dados de treino, como de validação;</li>
<li>Devemos garantir que estamos a selecionar opções de <em>sampling</em> de forma aleatória para utilizarmos nos conjuntos de treino e de validação. Se os dados estiverem ordenados por algum atributo então os dados a validar podem ter atributos não representados nos dados de treino;</li>
<li>Fazer <em>cross-validation</em> de forma a fazer com que todos os dados tenham a oportunidade de ser representados tanto nos conjuntos de treino e de validação.</li>
</ol>
</li>
<li>Um <em>dataset</em> de validação que possa ser demasiado pequeno relativamente aos dados de treino pode ser demonstrado por uma curva de aprendizagem para <em>training loss</em> que aparenta ser um bom <em>fit</em> e uma curva de aprendizagem para <em>validation loss</em> que mostra movimentos de ruído à volta da <em>training loss</em>.
<ol>
<li>Adicionar mais observações ao <em>dataset</em> de validação;</li>
<li>Se estivermos num número limitado de observações, devemos fazer <em>cross-validation</em> de forma a que todos os dados tenham oportunidade de serem representados nos conjuntos de treino e de validação.</li>
</ol>
</li>
<li>Um conjunto de validação que seja mais fácil de prever que o conjunto de dados de treino pode ser identificado pela <em>validation loss</em> que é menor que a <em>training loss</em>.
<ol>
<li>Verificar que não se tem observações duplicadas entre os <em>datasets</em> de treino e de validação;</li>
<li>Verificar que não existe fuga de informação entre os <em>datasets</em> de treino e de validação;</li>
<li>Verificar que se estão a escolher amostras aleatórios, para que a variância dos atributos seja consistente em ambos os conjuntos;</li>
<li>Fazer <em>cross-validation</em> de forma a fazer com que todos os dados tenham a oportunidade de ser representados tanto nos conjuntos de treino e de validação.</li>
</ol>
</li>
</ol>
<h2 id="redes-neuronais-artificiais-1"><a class="header" href="#redes-neuronais-artificiais-1">Redes Neuronais Artificiais</a></h2>
<ul>
<li><strong>Pontos Fortes</strong>:
<ul>
<li>A <em>accuracy</em> de problemas de classificação é geralmente elevada para problemas complexos;</li>
<li>Processamento distribuído, o conhecimento é distribuído pelos pesos das conexões;</li>
<li>Robusto a lidar com exemplos, mesmo que estes contenham erros;</li>
<li>Lida bem com atributos redundantes, desde que o peso associado a eles seja pequeno;</li>
<li>Resultados podem ser discretos, valores reais ou um vetor de valores (discretos ou reais).</li>
</ul>
</li>
<li><strong>Pontos Fracos</strong>:
<ul>
<li>Dificuldade em determinar a topologia de rede ótima para um problema;</li>
<li>Dificuldade para usar, pois tem muitos parâmetros para definir;</li>
<li>Precisa de pré-processamento específico de dados;</li>
<li>Precisa de muito tempo para treino;</li>
<li>Dificuldade a aprender a função de aprendizagem (pesos);</li>
<li>Conhecimento descoberto não pode ser lido;</li>
<li>Não providencia explicações para os resultados;</li>
<li>A incorporação do domínio de conhecimento não é fácil.</li>
</ul>
</li>
</ul>
<h2 id="frameworks"><a class="header" href="#frameworks"><em>Frameworks</em></a></h2>
<ul>
<li>Componentes fundamentais em qualquer <em>framework</em> DL:
<ul>
<li><em>The Tensor Object</em>;</li>
<li>Operações no <em>Tensor Object</em>;</li>
<li>Computação e otimização de grafos;</li>
<li>Ferramentas de diferenciação automática;</li>
<li>Extensões BLAS/cuBLAS e cuDNN.</li>
</ul>
</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="chapter_7.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>
                            <a rel="next" href="chapter_9.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="chapter_7.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>
                    <a rel="next" href="chapter_9.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
    </body>
</html>
